---
title: "Practical Machine Learning"
output: html_document
---

### 1 - Description
Six participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways while accelerometers on the belt, forearm, arm, and dumbell measured their performance. The original study and data can be found [here](http://groupware.les.inf.puc-rio.br/har) under the section on the Weight Lifting Exercise Dataset.

The goal of this project is to predict the manner in which they did the exercise, the 'classe' variable, which can be either of five qualitative values: A, B, C, D or E.

### 2 - Data Cleaning

Including the outcome variable, the data set contains 11,776 observations and 160 variables. However, a quick exploration of the data shows that there is a huge amount of missing values and that they are concentrated in specific variables. No explanation is provided about why there are so many missing values although in fact they affect a large percentage of the data set. In 73 of the variables 98% of the observations are missing values, and in another 27 they reach 100%.
  
It would be possible to impute missing values using the existing ones but it seems far-fetched to recreate 98% of the data using the existing 2%. Therefore, they will be simply removed from the training data.

Additionally, there are other seven variables not relevant to the model. They contain information on the observation's id, subject's name, time stamps and observation windows. These represent values not directly related with the performance of the exercises and they would become meaningless once the model is fit to new data.

In summary, as a result, including the outcome variable there remain 53 variables to train a machine learning model (see fig.1).

### 3 - Model selection
Before training different models to fit the data, the clean training data was split into training, testing and validation sets, which corresponded respectively to 60, 20 and 20% of the original training data.

#### 3.1 - Model training
Initially a classification tree model was fit to the training set, however, the results were very poor. The in-sample accuracy was 49.91%, and , logically, it performed equally poor on the testing and validation sets with a 49.38% and 48.69% accuracy respectively.

The next model fitted was a random forest with all variables, 52 plus the outcome, using the default settings, which uses bootstrapping with 25 repetitions and generates 500 trees. It provided an impressing 0.87% OOB error estimate. The downside was the relatively long time to perform the calculations. In contrast a 5-fold cross validation model using the same number of trees was indeed much faster and the results quite similar. The OOB was 0.94%.

One way to increase the efficiency of the model was to inspect the relative importance of the variables used. Since not all variables are equally significant it seemed possible to reduce the number of variables without losing predictive accuracy.

```{r variable importance, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
library(ggplot2)
ggplot(sort_importance_asc, aes(x=var, y=MeanDecreaseGini)) +
        geom_bar(stat="identity", fill="red", colour="white") +
        coord_flip() +
        xlab("Variables") +
        ylab("Mean Decrease Gini") +
        ggtitle("figure 1 - Variable importance")
```

#### 3.2 Model comparison
Several models were fitted using the variable importance data in a descending order. The first one was restricted to the 26 most important variables, 50% of the original 52 variables. Subsequently, each of the following models used half the number of variables of the preceding one.

Although there is a downward trend in accuracy as the number of variables decreases, it is outstanding how each subsequent model using just half of the variables used in the preceding one display almost as much accuracy until the variables are reduced to only 4. It is also noteworthy how 5-fold cross validation is just as accurate as a bootstrap model but requires much less computing power, which makes it much more efficient.  
  
**Figure 2 - Comparison table**  
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border:none;margin:0px auto;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}
.tg .tg-3zgm{background-color:#343434;color:#ffffff}
.tg .tg-aq88{background-color:#343434;color:#ffffff;text-align:center}
.tg .tg-s6z2{text-align:center}
.tg .tg-0ord{text-align:right}
.tg .tg-2thk{background-color:#c0c0c0;text-align:center}
.tg .tg-tkkh{background-color:#c0c0c0;text-align:right}
.tg .tg-hy62{background-color:#c0c0c0}
</style>
<table class="tg">
  <tr>
    <th class="tg-3zgm"></th>
    <th class="tg-3zgm"></th>
    <th class="tg-aq88">Error estimate %<br>OOB<br></th>
    <th class="tg-aq88">Accuracy %<br>Testing<br></th>
    <th class="tg-aq88">Accuracy %<br>Validation</th>
  </tr>
  <tr>
    <td class="tg-s6z2">52 variables<br></td>
    <td class="tg-0ord">Bootstrap<br></td>
    <td class="tg-s6z2">0.87</td>
    <td class="tg-s6z2">98.94</td>
    <td class="tg-s6z2">99.08</td>
  </tr>
  <tr>
    <td class="tg-s6z2"></td>
    <td class="tg-0ord">5-fold CV<br></td>
    <td class="tg-s6z2">0.94</td>
    <td class="tg-s6z2">99.26</td>
    <td class="tg-s6z2">99.03</td>
  </tr>
  <tr>
    <td class="tg-2thk">26 variables<br></td>
    <td class="tg-tkkh">Bootstrap<br></td>
    <td class="tg-2thk">0.83</td>
    <td class="tg-2thk">99.18</td>
    <td class="tg-2thk">98.93</td>
  </tr>
  <tr>
    <td class="tg-2thk"></td>
    <td class="tg-tkkh">5-fold CV<br></td>
    <td class="tg-2thk">0.82</td>
    <td class="tg-2thk">99.31<br></td>
    <td class="tg-2thk">98.98</td>
  </tr>
  <tr>
    <td class="tg-s6z2">13 variables<br></td>
    <td class="tg-0ord">Bootstrap<br></td>
    <td class="tg-s6z2">1.74</td>
    <td class="tg-s6z2">98.37</td>
    <td class="tg-s6z2">98.57</td>
  </tr>
  <tr>
    <td class="tg-s6z2"><br></td>
    <td class="tg-0ord">5-fold CV<br></td>
    <td class="tg-s6z2">1.65<br></td>
    <td class="tg-s6z2">98.39</td>
    <td class="tg-s6z2">98.27</td>
  </tr>
  <tr>
    <td class="tg-2thk">7 variables<br></td>
    <td class="tg-tkkh">Bootstrap<br></td>
    <td class="tg-2thk">1.92<br></td>
    <td class="tg-2thk">98.52</td>
    <td class="tg-2thk">98.78</td>
  </tr>
  <tr>
    <td class="tg-hy62"></td>
    <td class="tg-tkkh">5-fold CV<br></td>
    <td class="tg-2thk">1.88</td>
    <td class="tg-2thk">98.16</td>
    <td class="tg-2thk">98.32</td>
  </tr>
    <tr>
    <td class="tg-s6z2">4 variables<br></td>
    <td class="tg-0ord">Bootstrap<br></td>
    <td class="tg-s6z2">6.8<br></td>
    <td class="tg-s6z2">93.02</td>
    <td class="tg-s6z2">92.74</td>
  </tr>
  <tr>
    <td class="tg-s6z2"><br></td>
    <td class="tg-0ord">5-fold CV<br></td>
    <td class="tg-s6z2">6.93</td>
    <td class="tg-s6z2">92.86</td>
    <td class="tg-s6z2">92.66</td>
  </tr>
</table>

### 4 Final model
The accuracy rate as less and less variables are included in the model decreases most appreciably when only the 4 most significant variables are used. However, a model with the 7 most important variables and fitting a 5-fold cross validation model yields excellent results in terms of OOB error estimate and final predicting accuracy, while being very efficient in terms of computing power.


**Model fit:**

        fitControl <- trainControl(method="cv", number=5)
        
        final_model <- train(classe ~ roll_belt + pitch_forearm + yaw_belt + magnet_dumbbell_y +
                                pitch_belt + magnet_dumbbell_z + roll_forearm, 
                                data = training,
                                trControl = fitControl)


**Model fit summary:**

        Random Forest 

        11776 samples
        7 predictor
        5 classes: 'A', 'B', 'C', 'D', 'E' 

        No pre-processing
        Resampling: Cross-Validated (5 fold) 

        Summary of sample sizes: 9420, 9420, 9421, 9421, 9422 

        Resampling results across tuning parameters:

        mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
        2     0.979     0.973  0.00268      0.00338 
        4     0.979     0.973  0.00166      0.00210 
        7     0.972     0.965  0.00311      0.00393 

        Accuracy was used to select the optimal model using  the largest value.
        The final value used for the model was mtry = 2. 


**Final model summary:**

        Call:
        randomForest(x = x, y = y, mtry = param$mtry) 
                       Type of random forest: classification
                             Number of trees: 500
        No. of variables tried at each split: 2

                OOB estimate of  error rate: 1.88%
        Confusion matrix:
        A    B    C    D    E class.error
        A 3301   21   22    3    1  0.01403823
        B   28 2201   36   11    3  0.03422554
        C    4   17 2018   15    0  0.01752678
        D    0    3   21 1903    3  0.01398964
        E    1   22    6    4 2132  0.01524249